{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         volume \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter volume (0.0 to 1.0): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m         player\u001b[38;5;241m.\u001b[39mset_volume(volume)\n\u001b[1;32m     60\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)  \u001b[38;5;66;03m# Give a small delay to ensure the volume change takes effect\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from threading import Thread, Event\n",
    "import time\n",
    "\n",
    "class AudioPlayer:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.audio_segment = AudioSegment.from_file(file_path)\n",
    "        self.volume = 1.0  # Default volume (1.0 is 100%)\n",
    "        self.chunk_size = 1024  # 1KB chunks for playback\n",
    "        self.stream = None\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stop_event = Event()\n",
    "        self.play_thread = Thread(target=self._play_loop)\n",
    "        self.play_thread.start()\n",
    "\n",
    "    def _play_loop(self):\n",
    "        audio_data = np.array(self.audio_segment.get_array_of_samples())\n",
    "        sample_width = self.audio_segment.sample_width\n",
    "        channels = self.audio_segment.channels\n",
    "        rate = self.audio_segment.frame_rate\n",
    "        audio_format = self.p.get_format_from_width(sample_width)\n",
    "        num_samples = len(audio_data)\n",
    "\n",
    "        if self.stream is None:\n",
    "            self.stream = self.p.open(format=audio_format,\n",
    "                                      channels=channels,\n",
    "                                      rate=rate,\n",
    "                                      output=True)\n",
    "\n",
    "        idx = 0\n",
    "        while not self.stop_event.is_set():\n",
    "            end_idx = min(idx + self.chunk_size, num_samples)\n",
    "            chunk = audio_data[idx:end_idx]\n",
    "            chunk = (chunk * self.volume).astype(np.int16)\n",
    "            self.stream.write(chunk.tobytes())\n",
    "            idx = end_idx if end_idx < num_samples else 0\n",
    "\n",
    "    def set_volume(self, volume):\n",
    "        self.volume = volume\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_event.set()\n",
    "        if self.stream is not None:\n",
    "            self.stream.stop_stream()\n",
    "            self.stream.close()\n",
    "        self.p.terminate()\n",
    "        self.play_thread.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"city_noise.mp3\"  # Change this to your audio file path\n",
    "    player = AudioPlayer(file_path)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            volume = float(input(\"Enter volume (0.0 to 1.0): \"))\n",
    "            player.set_volume(volume)\n",
    "            time.sleep(0.1)  # Give a small delay to ensure the volume change takes effect\n",
    "    except KeyboardInterrupt:\n",
    "        player.stop()\n",
    "        print(\"Audio playback stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerome/Uni_Master/SonicThinking/sonicthinking/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.30 ðŸš€ Python-3.9.6 torch-2.2.2 CPU (Intel Core(TM) i5-4288U 2.60GHz)\n",
      "YOLOv8m-cls summary (fused): 103 layers, 15767780 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'be-mine-or-clsm.pt' with input shape (1, 3, 256, 256) BCHW and output shape(s) (1, 4) (30.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2024.1.0-15008-f4afc983258-releases/2024/1...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success âœ… 7.0s, saved as 'be-mine-or-clsm_openvino_model/' (60.3 MB)\n",
      "\n",
      "Export complete (11.6s)\n",
      "Results saved to \u001b[1m/Users/jerome/Uni_Master/SonicThinking\u001b[0m\n",
      "Predict:         yolo predict task=classify model=be-mine-or-clsm_openvino_model imgsz=256  \n",
      "Validate:        yolo val task=classify model=be-mine-or-clsm_openvino_model imgsz=256 data=/home/jerome/datasets/be-mine-or-1  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'be-mine-or-clsm_openvino_model'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a YOLOv8n PyTorch model\n",
    "model = YOLO(\"be-mine-or-clsm.pt\")\n",
    "\n",
    "# Export the model\n",
    "model.export(format=\"openvino\", imgsz=256, half=True)  # creates 'yolov8n_openvino_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openvino.inference_engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenvino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IECore\n\u001b[1;32m      3\u001b[0m ie \u001b[38;5;241m=\u001b[39m IECore()\n\u001b[1;32m      4\u001b[0m net \u001b[38;5;241m=\u001b[39m ie\u001b[38;5;241m.\u001b[39mread_network(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe-mine-or-clsm_openvino_model/be-mine-or-clsm.xml\u001b[39m\u001b[38;5;124m'\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe-mine-or-clsm_openvino_model/be-mine-or-clsm.bin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openvino.inference_engine'"
     ]
    }
   ],
   "source": [
    "from openvino.inference_engine import IECore\n",
    "\n",
    "ie = IECore()\n",
    "net = ie.read_network(model='be-mine-or-clsm_openvino_model/be-mine-or-clsm.xml', weights='be-mine-or-clsm_openvino_model/be-mine-or-clsm.bin')\n",
    "input_layer = next(iter(net.input_info))\n",
    "print(\"Input layer shape: \", net.input_info[input_layer].input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Name: x\n",
      "Input Shape: [1,3,256,256]\n",
      "Input Precision: <Type: 'float32'>\n",
      "Assumed Layout: NCHW or NHWC depending on model specification.\n"
     ]
    }
   ],
   "source": [
    "import openvino.runtime as ov\n",
    "\n",
    "# Initialize OpenVINO runtime core\n",
    "core = ov.Core()\n",
    "\n",
    "# Read the model\n",
    "model = core.read_model('be-mine-or-clsm_openvino_model/be-mine-or-clsm.xml', 'be-mine-or-clsm_openvino_model/be-mine-or-clsm.bin')\n",
    "\n",
    "# Get the input information\n",
    "input_info = model.inputs[0]  # Assuming the model has one input. Adjust if there are multiple inputs.\n",
    "\n",
    "# Get input name\n",
    "input_name = input_info.get_any_name()\n",
    "\n",
    "# Get input shape\n",
    "input_shape = input_info.get_shape()\n",
    "\n",
    "# Get input precision\n",
    "input_precision = input_info.get_element_type()\n",
    "\n",
    "# Layout is not directly accessible, but you can deduce it from the shape and model context\n",
    "# For instance, a common input shape for image data is [N, C, H, W], indicating an NCHW layout.\n",
    "\n",
    "# Print input details\n",
    "print(f\"Input Name: {input_name}\")\n",
    "print(f\"Input Shape: {input_shape}\")\n",
    "print(f\"Input Precision: {input_precision}\")\n",
    "\n",
    "# You might want to print layout assumptions based on the shape\n",
    "if len(input_shape) == 4:\n",
    "    print(\"Assumed Layout: NCHW or NHWC depending on model specification.\")\n",
    "elif len(input_shape) == 3:\n",
    "    print(\"Assumed Layout: CHW or HWC depending on model specification.\")\n",
    "# Add more conditions based on common model input shapes if necessary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sonicthinking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
